![[Lab11_linux.pdf]]

---

# Перед выполнением последующих заданий...

Для внесения ястности в происходящее, отмеучу, что перед выполнением заданий для улучшения репрезентативности результатов выполнения последующих алгоритмов я в домашнюю директорию распаковал архив с какими-то картинками на 100 Мб.

Для чего это нужно? Потому что до того, как я это сделал, домашняя директория на тестовой системе состояла исключительно из текстовых файлов. Они слишком хорошо поддаются сжатию.

Захотелось усложнить работу алгоритмам, добавив побольше бинарных данных.

![[linlab11_pre.png]]

# Задание 1. Мучаемся с tar.gz\/bz2\/xz

**Создание tar-архива.**

Для создания tar-архива можно использовать следующую команду `tar` с ключами `cvf`. Также предусмотрим эдакое псевдо-версионирование, добавив к названию архива текущие дату и время: 

```bash
tar -cvf /backup/home_$(date '+%Y_%m_%d_%H_%M_%S').tar ~
```

**Проверка архива на целостность.**

Для проверки архива не целостность можем воспользоваться ключом `-t` утилиты `tar`:

1. Для алгоритма gzip - с ключом `-z`:
	````bash
	tar -tvzf my_tar.tar.gz >/dev/null && echo "Backup is good!"
	````
2. Для алгоритма bzip2 - с ключом `-j`:
	```bash
	tar -tvjf my_tar.tar.gz >/dev/null && echo "Backup is good!"
	```
3. Для алгоритма xz - с ключом `-J`:
	```bash
	tar -tvJf my_tar.tar.gz >/dev/null && echo "Backup is good!"
	```
4. Для любого из вышеприведённых (или без сжатия) автоматически, без ключа:
	```bash
	tar -tvf my_tar.tar.compressed >/dev/null && echo "Backup is good!"
	```

Проверим, как эти команды работают, на практике:

![[linlab11_task1_check.png]]

Прочие операции над сжатыми архивами приведены в таблице. После неё следуют примечания по каждому показавшемуся мне интересному пункту:

| |Operation|gzip|bzip2|xz|
|---|---|---|---|---|
|1. |**Compression**|<span style="color: cyan">gzip</span> -k /backup/home.tar|<span style="color: cyan">bzip2</span> -k /backup/home.tar|<span style="color: cyan">xz</span> -k /backup/home.tar|
| | **<span style="color: #dc506c;">Directly tar</span>** | tar -cv<span style="color: cyan; font-size: 1.3em">z</span>f /backup/home_\$(date +\%Y\%m\%d_\%H\%M\%S).tar.gz ~ | tar -cv<span style="color: cyan; font-size: 1.3em">j</span>f /backup/home_\$(date +\%Y\%m\%d_\%H\%M\%S).tar.bz2 ~ | tar -cv<span style="color: cyan; font-size: 1.3em">J</span>f /backup/home_\$(date +\%Y\%m\%d_\%H\%M\%S).tar.xz ~ |
|2. |**Decompression**|<span style="color: cyan">gunzip</span> -c /backup/home.tar.gz \| tar xvf - -C ~|<span style="color: cyan">bunzip2</span> -c /backup/home.tar.bz2 \| tar xvf - -C ~|<span style="color: cyan">unxz</span> -c /backup/home.tar.xz \| tar xvf - -C ~|
| | **<span style="color: #dc506c;">Directly tar</span>** | tar -xv<span style="color: cyan; font-size: 1.3em">z</span>f /backup/home.tar.gz ~ | tar -xv<span style="color: cyan; font-size: 1.3em">j</span>f /backup/home.tar.bz2 ~ | tar -xv<span style="color: cyan; font-size: 1.3em">J</span>f /backup/home.tar.xz ~ |
| | **<span style="color: #dc506c;">Directly tar<br></span><span style="color: cyan">No extra keys</span>** | tar -xvf /backup/home.tar.*compressed* ~ | *Same* | *Same* |
|3. |**List contents**|<span style="color: cyan">gunzip</span> -c /backup/home.tar.gz \| tar tf -|<span style="color: cyan">bunzip2</span> -c /backup/home.tar.bz2 \| tar tf -|<span style="color: cyan">unxz</span> -c /backup/home.tar.xz \| tar tf -|
| | **<span style="color: #dc506c;">Directly tar</span><br><span style="color: cyan">No extra keys</span>** | tar -tf /backup/home.tar.*compressed* | *Same* | *Same* |
|4. |**Add file to archive**|gunzip /backup/home.tar.gz && tar rf /backup/home.tar newfile && gzip /backup/home.tar|bunzip2 /backup/home.tar.bz2 && tar rf /backup/home.tar newfile && bzip2 /backup/home.tar|unxz /backup/home.tar.xz && tar rf /backup/home.tar newfile && xz /backup/home.tar|
|5. |**Remove file from archive**|gunzip /backup/home.tar.gz && tar --delete -f /backup/home.tar oldfile && gzip /backup/home.tar|bunzip2 /backup/home.tar.bz2 && tar --delete -f /backup/home.tar oldfile && bzip2 /backup/home.tar|unxz /backup/home.tar.xz && tar --delete -f /backup/home.tar oldfile && xz /backup/home.tar|
|6. |**Compression ratio**|printf "ratio: " && echo "scale=2; $(wc -c < /backup/home.tar.*compressed*) * 100 / $(wc -c < /backup/home.tar)" \| bc|*Same*|*Same*|

**Примечание 0. О мусоре в голове** 

При просмотре таблицы советую не обращать внимание на все вхождения ключа `v` для утилиты `tar`. Его расшифровка - `verbose`. Иначе говоря, он нужен только для того, чтобы получить подробную информацию о ходе работы утилиты в консоли.

## Примечание 1. О работе с сжатыми архивами непосредственно через tar

На самом деле, как можно видеть из таблицы, **современный** `tar` поддерживает большую часть операций с сжатыми архивами нативно. Приведём пояснения по операциям из таблицы, которые можно выполнить двумя способами:

**1. Создание сжатого архива.**

С одной стороны, мы можем сначала создать архив `tar`, и затем сжать нужным алгоритмом через соответствующую утилиту. С другой стороны, мы можем создать сжатый архив непосредственно через утилиту `tar` следующим образом:

1. Для алгоритма gzip - с ключом `-z`:
	````bash
	tar -cvzf /backup/home_$(date +%Y%m%d_%H%M%S).tar.gz ~
	````
2. Для алгоритма bzip2 - с ключом `-j`:
	```bash
	tar -cvjf /backup/home_$(date +%Y%m%d_%H%M%S).tar.bz2 ~
	```
3. Для алгоритма xz - с ключом `-J`:
	```bash
	tar -cvJf /backup/home_$(date +%Y%m%d_%H%M%S).tar.xz ~
	```
4. При необходимости указания степени сжатия (от 0 до 9), добавляем числовой ключ, например одним из следующих образов:
	```bash
	tar -cvzf9 /backup/home_$(date +%Y%m%d_%H%M%S).tar.gz ~
	```
	```bash
	tar -cvzf -9 /backup/home_$(date +%Y%m%d_%H%M%S).tar.gz ~
	```

**2. Разархивация сжатого архива.**

В случае восстановления данных из сжатого архива ситуация полностью аналогична ситуации из предыдущего пункта:
езно читать компьютерные книжки. Надо как-нибудь это попробова
1. Для алгоритма gzip - с ключом `-z`:
	````bash
	tar -xvzf /backup/home.tar.gz ~
	````
2. Для алгоритма bzip2 - с ключом `-j`:
	```bash
	tar -xvjf /backup/home.tar.bz2 ~
	```
3. Для алгоритма xz - с ключом `-J`:
	```bash
	tar -xvJf /backup/home.tar.xz ~
	```

Однако tar достаточно интеллектуален и мы, на самом деле, можем не указывать алгоритм сжатия. В таком случае, tar определит его автоматически:

````bash
tar -xvf /backup/home.tar.gz ~
````

````bash
tar -xvf /backup/home.tar.bz2 ~
````

````bash
tar -xvf /backup/home.tar.xz ~
````

**3. Отображение списка файлов в сжатом архиве.**

Ситуация опять аналогична. В современности `tar` обладает возможностью просмотра списка файлов в сжатых архивах без непосредственной декомпрессии. Более того, мы он даже алгоритм сжатия может определить полностью автоматически. Таким образом, нам для всех случаев достаточно `tar -tf archive_name.tar.ABC`.

Рассмотрим оба метода и убедимся в их равнозначности:

![[linlab11_task1_listfiles.png]]

![[linlab11_task1_listfiles_directly.png]]

**4. Однако всё хорошее имеет свойство заканчиваться.**

Как бы не могло показаться, но tar не всемогущ в плане работы со сжатыми архивами. Например, добавить в такой архив файл или удалить он уже не может. :(

Всё, что в наших силах - сначала убрать сжатие, затем выполнить операцию над архивом, и далее сжать его обратно.

В целом, это уважаемо: изменить сжатый архив не так просто. Учитывая сложность алгоритмов сжатия и их статистическую природу, я даже могу предположить, что изменение в начале архива могут привести к изменению байтов в конце сжатого архива. Иначе говоря, изменение сжатого архива, скорее всего, в любом случае повлекло бы его полную перезапись. 

И всё равно обидно. От нас, как пользователя, это вполне можно было бы спрятать под капотом. Правда тогда бы мы сильно удивлялись долгому времени работы каждой мелкой операции. 

## Примечание 2. О структуре директорий

Вот мы выбрали файлы, сделали архив. А в него записалась вся структура директорий начиная от корня. Наверное, нехорошо? Для бекапов хорошо. А так, нет.

Если мы хотим указать "корень" архива, пользуемся ключом `--directory`:

````bash
tar -czf /backup/home.tar --directory=/home/username
````

Допустим, у нас всё-таки архив без указанной директории. То есть все файлы в нём имеют путь аж от корня. Мы его разархивируем - и где бы ни был архив, они встанут на своё место. Но иногда нам такое поведение не к рукам. Может быть, у нас на диске есть важные данные, а tar их возьмёт - и перезапишет. 

В таком случае, конкретную выходную директорию мы можем указать при помощи ключа `-C`:

![[linlab11_task1_decompress_to_path.png]]

## Примечание 3. Об определении степени сжатия архивов

Как ни прискорбно, ни tar, ни какая-либо из утилит gz, bzip2, xz не имеют ключей для определения степени сжатия заранее. 

Таким образом, чтобы определить степень сжатия нужно сначала создать сжатый архив, и затем сравнить его размер с изначальным. 

Я предлагаю это делать при помощи утилиты `du` для определения размера файлов и утилиты `bc`, которая позволяет считать числовые выражения из `stdout` через pipe. По сути, предлагаю воспользоваться консольным калькулятором.

Давайте сразу на месте и сравним степень сжатия архивов разными алгоритмами (и с разной указанной силой сжатия):

![[linlab11_task1_compression.png]]

![[linlab11_task1_extreme_compression.png]]

Алгоритм xz крайне напрягал своим долгим сжатием - и оправдал надежды. В случае необходимости сильного сжатия, он оказался лучше всех. Для алгоритмов gz и bzip2 разницы я почти не увидел.

# Задание 2. Не мучаемся c dd

`dd` предназначен для конвертирования и копирования файлов. Поэтому он отлично подходит в том числе для копирования данных на целом разделе. Причина тому в том, что с точки зрения ОС Linux раздел на жёстком диске - это блочный файл.

В указаниях к лабораторной работе сказано сделать копию раздела, который применялся в лабораторной работе по LVM. Увы, я его потёр. Продемонстрируем работу dd на примере раздела `/dev/sda2`, который в моём случае является EFI-разделом:

![[linlab11_task2_lsblk.png]]

## 1. Скопируем раздел в файл

```bash
dd if=/dev/sda2 of=/backup/dev_sda2
```

![[linlab11_task2_1_backup.png]]

## 2. Скопируем файл в раздел

Представим, что у нас что-то сломалось.

```bash
dd if=/backup/dev_sda2 of=/dev/sda2
```

![[linlab11_task2_2_unbackup.png]]

Я перезагрузился, всё проверил. Ничего даже не сломалось!

## 3. А могло ли что-то сломаться?

Конечно могло! Поскольку мы просто копируем весь раздел со структурой файловой системы, а затем обратно, мы негласно заключаем контракт о размере файловой системы и о размере раздела.

1. Если бы мы перед восстановлением уменьшили бы раздел, последствия были бы непредсказуемы. 
2. Если бы мы перед восстановлением увеличили бы раздел, всё было бы, скорее всего, в порядке, поскольку чисто фактически размер ФС и размер отдела - разные понятия. У нас бы просто осталось неиспользуемое пространство на разделе и далее нам бы требовалось для исправления ситуации вызвать `resize2fs`.
3. Вне зависимости от изменения размера ФС, но при одинаковом размере отдела, мы бы тоже не столкнулись с проблемами, поскольку просто перезаписали всю ФС, но тоже встали бы перед нуждой изменять размер ФС.

Поэтому таким способом создания резервных копий нужно пользоваться с осторожностью.

# Задание 3. Избавляемся от страданий с dump/restore

Поскольку раздел с системой у меня очень маленький и его резервная копия на него же не поместится, зато ещё с 10 лабораторной у меня остались разделы размером всего по 1Гб от RAID-массива, предварительно, перед выполнением задания, я возьму один из них (пусть это будет `/dev/sdb1`), отформатирую в ext4, вставлю пару файлов туда и буду делать именно его резервные копии. Далее будем исходить из этого.

Установим утилиты `dump`/`restore` из AUR:

```bash
yay --overwrie '*' -S dump
```

Почему `--overwrite`? Потому что файлом `/usr/bin/restore` уже владеет пакет `tar`. 

## 1. Создадим резервную копию ФС раздела

Поскольку это наш первый бекап, это бекап всей ФС. Поэтому мы ему определяем нулевой уровень `-0`.  Поскольку мы хотим автоматическое обновление журнала бекапов `/etc/dumpdates`, установим флаг `-u`.

```bash
dump -0 -f /backup/tape1 -A /backup/tape1.cat -u /dev/sdb1
```

Результат выполнения команды можно видеть на следующем скриншоте. Обратим внимание на то, что `/etc/dumpdates` действительно обновился. А в правом нижнем окне я вывел содержимое `tape1`. Если очень захотеть, там даже можно обнаружить содержимое наших файлов!

![[linlab11_task3_1_dump.png]]

## 2. Создадим инкрементальную копию ФС раздела

Допустим, мы внесли изменения в ФС, добавили какие-то файлы. Хотим ещё бекап.

Поскольку это наш второй бекап, а первый вроде никуда не делся, мы можем в резервную копию сохранить не все данные, а лишь те, что изменились. По этой причине установим бекапу 1 дочерний уровень флагом `-1`. Не забудем про автоматическое обновление журнала `-u`.

```bash
dump -1 -f /backup/tape2 -A /backup/tape2.cat -u /dev/sdb1
```

Смотрим, что произошло. Видм обновления в журнале, где новый бекап имеет уже 1 уровень, и видим, что в `tape2` действительно находится содержимое нового файла.

![[linlab11_task3_2_dump_incremental.png]]

**Как вообще работает система уровней бекапов?**

Вся суть в том, что бекап n-го уровня является как бы "ребёнком" самого-самого последнего бекапа (n-1)-го уровня и содержит все изменения, которые произошли по сравнению с ним.

В то же время бекап 0 уровня является всегда полным бекапом ФС, поскольку ниже 0 уровней нет и сравнивать не с чем. 

Исходя из предыдущих двух пунктов, мы понимаем, что можем настроить сколь угодно гибкую систему бекапов, например:

1. Каждый год мы можем создавать **ОГРОМНЫЙ** полный бекап ФС 0-го уровня
2. Каждые два месяца создавать **БОЛЬШОЙ** инкрементальный бекап 1-го уровня, в котором будут все изменения по сравнению с последним ОГРОМНЫМ ежегодным. 
3. Каждые две недели можем создавать **НИЧОТАКОЙ** бекап 2-го уровня, в котором будут все изменения по сравнению с последней БОЛЬШОЙ ежедвухмесячной версией.
4. Каждую рабочую неделю мы можем создавать **ТАКСЕБЕ** бекап 3-го уровня, в котором будут все изменения по сравнению с последней НИЧОТАКОЙ ежедвухнедельной версией.
5. И, наконец, каждый божий день создавать **ЛИЛИПУТСКИЙ** бекап 4-го уровня, в котором будут все изменения по сравнению с последней ТАКСЕБЕ еженедельной версией.

Как результат, у нас получится такая система резервных копий, что мы всегда держим наши бекапы актуальными, в случае инцидента не уходим на два года в прошлое, и при этом избыточность хранимых данных всё ещё является разумной. 

## 3. Хакеры всё удалили! Как восстановить?

[Процитирую](https://doc.lagout.org/operating%20system%20/linux/Nemet.pdf?page=361) Эви Немета, он будет не так многословен:

> Восстановив архив нулевого уровня, повторяйте процедуру для инкрементных архивов в том порядке, в каком они создавались. Поскольку всегда существует определенная избыточность, то, как правило, нет необходимости восстанавливать все инкрементные архивы. Вот примерная последовательность действий:
> 
>- Шаг 1: восстановите самый последний архив нулевого уровня.
>- Шаг 2: восстановите тот из оставшихся архивов, у которого наименьший уровень; если на данном уровне было создано несколько архивов, восстановите новейший из них.
>- Шаг 3: если это оказался самый последний архив, процедуру можно считать завершенной.
>- Шаг 4: в противном случае вернитесь к шагу 2.

**1\. Восстановим последний (и единственный) архив нулевого уровня:**

```bash
restore -r -f /backup/tape1
```

![[linlab11_task3_3_restore_1.png]]

**2\. Восстановим новейший из архивов 1 уровня:**

```bash
restore -r -f /backup/tape2
```

![[linlab11_task3_4_restore_2.png]]

**3\. Это был последний архив**

Вот и хорошо.

## 4. Хочу юзер-френдли

Для этого существует интерактивный режим. В нём предоставляется псевдо-терминальная среда, где мы можем ходить по дереву директорий и выбирать конкретные файлы/папки, которые подлежат восстановлению. Точно так же можно из всей папки исключить при восстановлении некий набор файлов.

**1\. Восстановим последний (и единственный) архив нулевого уровня:**

![[linlab11_task3_5_restore_i_1.png]]

**2\. Восстановим новейший из архивов 1 уровня:**

![[linlab11_task3_6_restore_i_2.png]]

# Задание 4.1. Окончательно устаём с Bacula

Серьёзно. А когда эта лабораторная закончится?

<span style="font-size: 2em; color: brown;">Нет. Bacula настраивать мы не будем. По крайней мере, не сегодня.
Этот раздел пропускаем, и переходим к следующему, поскольку условие лабораторной работы предлагает нам альтернативу попроще - CloneZilla.</span>

## 1. Установка пакетов

Bacula имеет масштабируемую архитектуру с множеством клиентов и (потенциально) множеством серверов. Серверная сторона Bacula состоит из следующих демонов:

1. `bacula-dir` - демон управления
2. `bacula-sd` - демон хранения
3. `bacula-fd` - демон файлов

Установим клиент на виртуальную машину:

```bash
# File daemon (client daemon)
yay -S bacula-fd
```

Обратим внимание на присутствие в AUR пакета `bacula-client`. Как я понимаю, этот пакет представляет из себя обыкновенный alias на `bacula-fs`.

Установим демоны на основную машину (пользоваться супер-масштабируемостью Bacula не будем):

```bash
# Common files
yay -S bacula-common
# Director
yay -S bacula-dir
# Postgresql support for director
yay -S bacula-dir-postgresql
# Storage daemon
yay -S bacula-sd
# File daemon
yay -S bacula-fd
```

Все эти пакеты относятся к единственному PKGBUILD, из чего следует, что сборку ожидать нам придётся всего один раз (вместо ожидаемых мной пяти). Однако, приятно!

Обратим внимание, что на сервер я также установил `bacula-fd`. Это не обязательно. Установил на случай, если появится настроение настроить резервное копирование в том числе для своей основной системы. И это вряд ли.

Также на основную машину установим утилиты администрирования Bacula:

```bash
# Management CLI
yay -S bacula-console
# Management GUI
yay -S bacula-bat
```

И базу данных Postgresql:

```bash
sudo pacman -S postgresql
```

Убедимся, что все демоны установились и управляемы через `systemctl`:

![[linlab11_bacula_installed.png]]
## 2. Конфигурирование Bacula


# Задание 4.2. Вздыхаем с облегчением с CloneZilla.

## 1. Устанавливаем виртуальную машину

Да, я тут решил её немного переустановить, поскольку при резервном копировании CloneZilla мы будем копировать раздел целиком. И с одним разделом на 30 гигов это будет не очень удобно.

>[!blank | alt]
>>[!blank | gallery]
>>![[Pasted image 20240115171615.png]]
>>![[Pasted image 20240115171647.png]]
>
>Выбираем таблицу разметки GPT и создаём 8Мб не отформатированный раздел с меткой bios-grub (что требуется для адекватной работы GPT в BIOS-системе, коей и является Virtualbox)
>
>![[Pasted image 20240115171919.png]]
>
>Вот так, по идее, может выглядеть таблица разделов

Здесь я создал, помимо основных системных разделов, также раздел `/boot` на гигабайт и `/home` на два гигабайта. Их и будем бекапить, они небольшие и удобные.

>[!blank | alt]
>![[Pasted image 20240115172906.png | center | 800]]
>
>Запустилось - значит всё настроили правильно

## 2. Подключим к нашей машине ещё один жёсткий диск

На него и будем сохранять вот эти всякие резервные копии.

>[!blank | alt]
>![[Pasted image 20240115173136.png | center | 800]]
>
>Вот так можно добавлять диски
>
>>[!blank | gallery]
>>![[Pasted image 20240115173212.png | center | 800]]
>>![[Pasted image 20240115173241.png | center | 800]]
>
>VDI на 5 гигабайт - точно то, что надо, поместится
>
>![[Pasted image 20240115173409.png | center | 800]]
>
>Должно получиться вот так

Проверим, как оно работает:

![[Pasted image 20240115174132.png | center | 800]]

Работает отлично, но наш жёсткий диск совершенно пуст. Нам там нужен хотя бы один раздел. Дело в том, что CloneZilla резервно копирует либо диск на диск, либо раздел на раздел. Поскольку мы хотим скопировать именно раздел, а не весь диск - нам нужен раздел и на резервном диске тоже.

Создадим на новом диске раздел:

![[Pasted image 20240115174734.png | center | 800]]

И отформатируем его в файловую систему ext4:

![[Pasted image 20240115180638.png | center | 800]]

Проверим, что получилось:

![[Pasted image 20240115180851.png | center | 800]]

Раздел создан, файловая система ext4. Всё хорошо.

## 3. Создаём резервную копию через CloneZilla

>[!blank | alt]
>![[Pasted image 20240115174900.png | center | 800]]
>
>Запускаем CloneZilla
>
>![[Pasted image 20240115174923.png | center | 800]]
>
>Делаем резервную копию с устройства на устройство. 
>А могли бы сохранять наш раздел не в другой раздел а, например, в образ на другом разделе. 
>У этого подхода тоже есть преимущества.
>
>![[Pasted image 20240115175013.png | center | 800]]
>
>Для начинающих
>
>![[Pasted image 20240115175028.png | center | 800]]
>
>Сохраняем раздел на раздел
>
>![[Pasted image 20240115175109.png | center | 800]]
>
>Копировать будем наш раздел `/home`
>
>![[Pasted image 20240115175138.png | center | 800]]
>
>И на раздел внешнего диска
>
>![[Pasted image 20240115175201.png | center | 800]]
>
>Проверку файловой системы пропускаем - хотя, по хорошему, не стоит!
>
>![[Pasted image 20240115175229.png | center | 800]]
>
>После окончания процесса - спросить, что делать.
>
>![[Pasted image 20240115175302.png | center | 800]]
>
>У нас спрашивают, уверены ли мы
>
>![[Pasted image 20240115175326.png | center | 800]]
>
>И снова, на случай, если у нас сегодня плохой день

<span style="font-size: 1.2em; color: brown;">Дальше, в моём случае, CloneZilla выдавал ошибку.</span> 
Что-то бла-бла с файловой системой, на которую мы осуществляем копирование. 
Не знаю, почему, но файловая система, куда я хотел сохранить копию, была повреждена. 
CloneZilla услужливо предложил перейти в терминал, где я ввёл `sudo fsck.ext4 /dev/sdX1` - она восстановилась, я перезагрузился, повторил предыдущие шаги - и на этот раз уже ошибок не было.

>[!blank | alt]
>![[Pasted image 20240115181821.png | center | 800]]
>
>Всё скопировалось успешно
>
>![[Pasted image 20240115181850.png | center | 800]]
>
>Осталось только нажать Enter и перезагрузиться

## 4. Перезагружаемся в систему и смотрим, что натворили

Посмотрим, что вообще теперь содержится в `/dev/sdb1`:

![[Pasted image 20240115183203.png | center | 800]]
![[Pasted image 20240115183227.png | center | 800]]

Ага, мы видим, что на резервный раздел было полностью скопировано содержимое оригинала. Это хорошо.

## 5. Попробуем что-нибудь сломать

Сделаем, чтобы файлы пропали:

![[Pasted image 20240115184122.png]]

## 6. А теперь пора чинить

Все шаги аналогичны предыдущему шагу, но диски меняются местами (а ещё я забыл сделать один из скриншотов):

![[Pasted image 20240115184424.png | center | 800]]

![[Pasted image 20240115184513.png | center | 800]]

## 7. Проверяем, как оно там починилось

![[Pasted image 20240115184730.png | center | 800]]

НОРМ.